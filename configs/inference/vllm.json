{
  "engine_name": "vllm",
  "engine_version": "0.7.3",
  "enabled": 1,
  "container_port": 8000,
  "model_format": "safetensors",
  "engine_images": [
    {
      "compute_type": "gpu",
      "image": "vllm-local:v0.7.3",
      "driver_version": "12.4"
    },
    {
      "compute_type": "cpu",
      "image": "vllm-cpu:2.4"
    }
  ],
  "engine_args": [
    { "name": "block-size", "value": "128", "format": "--block-size %s" },
    { "name": "dtype", "value": "auto", "format": "--dtype %s" },
    {
      "name": "gpu-memory-utilization",
      "value": "0.8",
      "format": "--gpu-memory-utilization %s"
    },
    {
      "name": "max-model-len",
      "value": "2048",
      "format": "--max-model-len %s"
    },
    {
      "name": "tensor-parallel-size",
      "value": "1",
      "format": "--tensor-parallel-size %s"
    },
    { "name": "max-num-seqs", "value": "256", "format": "--max-num-seqs %s" },
    {
      "name": "scheduling-policy",
      "value": "fcfs",
      "format": "--scheduling-policy %s"
    },
    { "name": "cpu-offload-gb", "value": "0", "format": "--cpu-offload-gb %s" },
    {
      "name": "pipeline-parallel-size",
      "value": "1",
      "format": "--pipeline-parallel-size %s"
    },
    {
      "name": "guided-decoding-backend",
      "value": "xgrammar",
      "format": "--guided-decoding-backend %s"
    },
    { "name": "swap-space", "value": "4", "format": "--swap-space %s" },
    { "name": "load-format", "value": "auto", "format": "--load-format %s" },
    {
      "name": "max-num-batched-tokens",
      "value": "4096",
      "format": "--max-num-batched-tokens %s"
    },
    {
      "name": "enable-prefix-caching",
      "value": "enable",
      "format": "--enable-prefix-caching"
    },
    {
      "name": "enable-chunked-prefill",
      "value": "enable",
      "format": "--enable-chunked-prefill"
    },
    { "name": "enforce-eager", "value": "enable", "format": "--enforce-eager" },
    {
      "name": "disable-custom-all-reduce",
      "value": "enable",
      "format": "--disable-custom-all-reduce"
    },
    {
      "name": "limit-mm-per-prompt",
      "value": "image=5,video=5",
      "format": "--limit-mm-per-prompt %s"
    }
  ],
  "supported_archs": [
    "AquilaForCausalLM",
    "ArcticForCausalLM",
    "BaiChuanForCausalLM",
    "BloomForCausalLM",
    "ChameleonForConditionalGeneration",
    "ChatGLMModel",
    "CohereForCausalLM",
    "DbrxForCausalLM",
    "DeciLMForCausalLM",
    "FalconForCausalLM",
    "FuyuForCausalLM",
    "GPT2LMHeadModel",
    "GPTBigCodeForCausalLM",
    "GPTJForCausalLM",
    "GPTNeoXForCausalLM",
    "Gemma2ForCausalLM",
    "GemmaForCausalLM",
    "InternLM2ForCausalLM",
    "InternLMForCausalLM",
    "InternVLChatModel",
    "JAISLMHeadModel",
    "JambaForCausalLM",
    "LlamaForCausalLM",
    "LlavaForConditionalGeneration",
    "LlavaNextForConditionalGeneration",
    "MPTForCausalLM",
    "MiniCPMForCausalLM",
    "MistralForCausalLM",
    "MixtralForCausalLM",
    "OLMoForCausalLM",
    "OPTForCausalLM",
    "OrionForCausalLM",
    "PaliGemmaForConditionalGeneration",
    "PersimmonForCausalLM",
    "Phi3ForCausalLM",
    "Phi3SmallForCausalLM",
    "Phi3VForCausalLM",
    "PhiForCausalLM",
    "QWenLMHeadModel",
    "Qwen2ForCausalLM",
    "Qwen2MoeForCausalLM",
    "Qwen2_5_VLForConditionalGeneration",
    "StableLmForCausalLM",
    "Starcoder2ForCausalLM",
    "XverseForCausalLM"
  ]
}
