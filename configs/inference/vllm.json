{
  "engine_name": "vllm",
  "enabled": 1,
  "container_port": 8000,
  "model_format": "safetensors",
  "engine_images": [
    {
      "compute_type": "gpu",
      "image": "opencsghq/vllm:v0.8.5",
      "driver_version": "12.4",
      "engine_version": "v0.8.5"
    },
    {
      "compute_type": "gpu",
      "image": "opencsghq/vllm:v0.8.5-cu121",
      "driver_version": "12.1",
      "engine_version": "v0.8.5"
    },
    {
      "compute_type": "gpu",
      "image": "opencsghq/vllm:v0.9.2-cu118",
      "driver_version": "11.8",
      "engine_version": "v0.9.2",
      "extra_archs":[
        "Ernie4_5_ForCausalLM",
        "Ernie4_5_MoeForCausalLM",
        "HunYuanDenseV1ForCausalLM",
        "HunYuanMoEV1ForCausalLM",
        "MiMoForCausalLM"
      ]
    },
    {
      "compute_type": "cpu",
      "image": "opencsghq/vllm-cpu:2.4",
      "engine_version": "0.4.12-fix1"
    }
  ],
  "engine_args": [
    { "name": "block-size", "value": "128", "format": "--block-size %s" },
    { "name": "dtype", "value": "auto", "format": "--dtype %s" },
    {
      "name": "gpu-memory-utilization",
      "value": "0.8",
      "format": "--gpu-memory-utilization %s"
    },
    {
      "name": "max-model-len",
      "value": "2048",
      "format": "--max-model-len %s"
    },
    {
      "name": "tensor-parallel-size",
      "value": "1",
      "format": "--tensor-parallel-size %s"
    },
    { "name": "max-num-seqs", "value": "256", "format": "--max-num-seqs %s" },
    {
      "name": "scheduling-policy",
      "value": "fcfs",
      "format": "--scheduling-policy %s"
    },
    { "name": "cpu-offload-gb", "value": "0", "format": "--cpu-offload-gb %s" },
    {
      "name": "pipeline-parallel-size",
      "value": "1",
      "format": "--pipeline-parallel-size %s"
    },
    {
      "name": "guided-decoding-backend",
      "value": "xgrammar",
      "format": "--guided-decoding-backend %s"
    },
    { "name": "swap-space", "value": "4", "format": "--swap-space %s" },
    { "name": "load-format", "value": "auto", "format": "--load-format %s" },
    {
      "name": "max-num-batched-tokens",
      "value": "4096",
      "format": "--max-num-batched-tokens %s"
    },
    {
      "name": "enable-prefix-caching",
      "value": "enable",
      "format": "--enable-prefix-caching"
    },
    {
      "name": "enable-chunked-prefill",
      "value": "enable",
      "format": "--enable-chunked-prefill"
    },
    { "name": "enforce-eager", "value": "enable", "format": "--enforce-eager" },
    {
      "name": "disable-custom-all-reduce",
      "value": "enable",
      "format": "--disable-custom-all-reduce"
    },
    {
      "name": "limit-mm-per-prompt",
      "value": "image=5,video=5",
      "format": "--limit-mm-per-prompt %s"
    }
  ],
  "supported_archs": [
    "AquilaForCausalLM",
    "ArcticForCausalLM",
    "BaiChuanForCausalLM",
    "BambaForCausalLM",
    "BertModel",
    "BloomForCausalLM",
    "BartForConditionalGeneration",
    "ChatGLMModel",
    "ChatGLMForConditionalGeneration",
    "CohereForCausalLM",
    "Cohere2ForCausalLM",
    "DbrxForCausalLM",
    "DeciLMForCausalLM",
    "DeepseekForCausalLM",
    "DeepseekV2ForCausalLM",
    "DeepseekV3ForCausalLM",
    "ExaoneForCausalLM",
    "FalconForCausalLM",
    "FalconMambaForCausalLM",
    "Gemma2Model",
    "GemmaForCausalLM",
    "Gemma2ForCausalLM",
    "Gemma3ForCausalLM",
    "GlmForCausalLM",
    "Glm4ForCausalLM",
    "GPT2LMHeadModel",
    "GPTBigCodeForCausalLM",
    "GPTJForCausalLM",
    "GPTNeoXForCausalLM",
    "GraniteForCausalLM",
    "GraniteMoeForCausalLM",
    "GraniteMoeSharedForCausalLM",
    "GritLM",
    "Grok1ModelForCausalLM",
    "InternLMForCausalLM",
    "InternLM2ForCausalLM",
    "InternLM3ForCausalLM",
    "JAISLMHeadModel",
    "JambaForCausalLM",
    "LlamaModel",
    "LlamaForCausalLM",
    "MambaForCausalLM",
    "MiniCPMForCausalLM",
    "MiniCPM3ForCausalLM",
    "MistralModel",
    "MistralForCausalLM",
    "MixtralForCausalLM",
    "MPTForCausalLM",
    "NemotronForCausalLM",
    "OLMoForCausalLM",
    "OLMo2ForCausalLM",
    "OLMoEForCausalLM",
    "OPTForCausalLM",
    "OrionForCausalLM",
    "PhiForCausalLM",
    "Phi3ForCausalLM",
    "Phi3SmallForCausalLM",
    "PhiMoEForCausalLM",
    "PersimmonForCausalLM",
    "Plamo2ForCausalLM",
    "QWenLMHeadModel",
    "Qwen2Model",
    "Qwen2ForCausalLM",
    "Qwen2MoeForCausalLM",
    "Qwen3ForCausalLM",
    "Qwen3MoeForCausalLM",
    "RobertaModel",
    "RobertaForMaskedLM",
    "StableLmForCausalLM",
    "Starcoder2ForCausalLM",
    "SolarForCausalLM",
    "TeleChat2ForCausalLM",
    "TeleFLMForCausalLM",
    "XverseForCausalLM",
    "XLMRobertaModel",
    "MiniMaxText01ForCausalLM",
    "Zamba2ForCausalLM"
  ]
}
